\documentclass[11pt,a4paper]{article}
\usepackage[bottom=2.3cm,top=2.3cm,left=2cm,right=2cm]{geometry}
\usepackage{ngerman}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{ae}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[pdftex]{graphicx}
\usepackage{float}
\usepackage{kpfonts,baskervald}
\usepackage{listings}
\usepackage{hyperref}
\renewcommand{\labelenumi}{\alph{enumi})}
\renewcommand{\labelenumii}{\roman{enumii})}
\newcommand{\Veranstaltung}[0]{Softwareprojekt Algorithmen der Computervision\\
	                           \large{Waggledance Detection}}
\newcommand{\Autoren}[0]{Roman Schulte-Sasse, Simon Auch, Johannes Sauer}

\lstset{language=C++}

%Titel, Autoren
\title{\Veranstaltung}
\author{\Autoren}
\date{\today}
\begin{document}
\maketitle

%% Beispiel für Codelisting, zum Testen aukommentieren:

%\begin{lstlisting}
%#include <stdio.h>
%#define N 10
%/* Block
% * comment */
%
%int main()
%{
%	int i;
%
% 	// Line comment.
% 	puts("Hello world!");
%
% 	for (i = 0; i < N; i++)
% 	{
%		puts("LaTeX is also great for programmers!");
% 	}
%
% 	return 0;
%}
%\end{lstlisting}

\section{Hardwaresetup}% Johannes

Bevor wir überhaupt mit dem algorithmischen Teil des Projekts, der Verbesserung bei der Erkennung der Schwänzeltänze,
anfangen konnten, war es zunächst notwendig die passende Hardware zu beschaffen.
Die verwendete Kamera stammte aus dem PlayStation Eye System und wurde schon vor unserem Projektstart ausgewählt um 
die Tänze zu detektieren, da sie eine außergewöhnliche hohe Aufzeichnungsrate von 100 Hz bei gleichzeitig niedrigem Preis bietet.

Leider ist das Objektiv dieser Kamera nicht auf die Maße der Aufbauten um den Bienenstock ausgerichtet.
Bei dem Setup zur Zeit unseres Projekts war geplant die Kamera ca. 70 bis 90 cm von dem Stock entfernt zu installieren.
Für diese Objektweite wurde ein Objektiv mit anderer Brennweite notwendig.
Da bei der PS Eye Kamera kein Austausch von Objektiven vorgesehen ist, musste der Aufbau über dem Sensor mit dem ursprünglichen
Objektiv zusammen entfernt werden und durch einen Neuen ersetzt werden.

\subsection{Kameramount}% Johannes

Da die PS Eye Kamera allgemein bei Bastlern beliebt ist, waren schon Mehrere vor uns auf die Idee gekommen das Kameragehäuse auszutauschen.
Deswegen sind CAD-Modelle zum 3D-Drucken für solche Gehäuse öffentlich verfügbar.
Bei unserem Projekt verwendeten wir ein \href{http://www.thingiverse.com/thing:83754}{Gehäuse für M12-Objektive}.
Wir konnten das Gehäuse mit dem 3D-Drucker der AG Secure Identity ausdrucken, der Druck selbst war problemlos.
Allerdings stellten wir später bei der Verwendung der modifizierten Kamera fest, dass das Schmelzschichtverfahren bei dem Druck
etwas an Genauigkeit zu wünschen übrig liess.
Das Objektiv hatte deshalb in dem Gewinde etwas zu viel Spiel und musste ab und zu nachjustiert werden, wenn das Licht nicht richtig
auf den Sensor fokussiert wurde.
Alles in allem war die Qualität des Gehäuses für unsere Zwecke jedoch ausreichend.

\subsection{Objektive}% Johannes

Die Wahl unserer Objektive war zum einen durch den schon beschriebenen Abstand zum Bienenstock und den M12-Mount beschränkt.
Da der Stock Ausmaße von ca. 30 cm $\times$ 40 cm hatte, ergab sich eine Brennweite von ca. 6 bis 7 mm.
Außerdem sollte das Objektiv das Bild möglichst wenig verzerren und keinen IR-Filter besitzen.
Da die Kombination dieser Eigenschaften etwas speziell ist hatten wir einige Zeit benötigt um eine gute Auswahl zu finden.
Letztendlich wurden wir von dem Versandhändler \href{http://www.lensation.de/}{Lensation} gut beraten und bekamen sogar mehrere Objektive
zum Testen ausgeliehen.
Eins davon passte gut zu den Anforderungen und wurde deswegen gekauft.

\section{Dotdetector}% Simon
Nachdem wir uns das erste mal in den Code und die Arbeit eingearbeitet und profiled haben wurde uns schnell klar, dass:
\begin{enumerate}
\item  Der Dotdetector einen Fehler hat
\item eine Formel genutzt wird welche sehr unintuitiv ist 
\item 90\% der Ausführungszeit auf den Dotdetector fällt
\item Die restlichen Layers das tun was Sie sollen\\
\end{enumerate}
Aufgrund dieser zwei Punkte haben wir uns entschlossen uns hauptsächlich auf den Dotdetector zu konzentrieren.

\subsection{Fehler der Frequenzanalyse-Berechnung}% Simon
Die Berechnung der Frequenzanalyse geschieht mit folgender Formel:
\begin{center}
\begin{equation} 
score(\bar{B}_j^n, r) = \sum_{1\le m\le b} (\bar{B}_j^n(m) * sin_r^m)^2+(\bar{B}_j^n(m) * cos_r^m)^2
\end{equation}
\begin{equation} 
score(\bar{B}_j^n, r) = \sum_{1\le m\le b} (\bar{B}_j^n(m)) ^2 * (sin_r^m) ^2+(\bar{B}_j^n(m)) ^2 * (cos_r^m) ^2
\end{equation}
\begin{equation} 
score(\bar{B}_j^n, r) = \sum_{1\le m\le b} (\bar{B}_j^n(m)) ^2 * ((sin_r^m) ^2+ (cos_r^m) ^2)
\end{equation}
\begin{equation} 
score(\bar{B}_j^n, r) = \sum_{1\le m\le b} (\bar{B}_j^n(m)) ^2
\end{equation}
\end{center}

Das diese Formel keine Frequenzanalyse darstellt dürfte einleuchtend sein, weswegen wir die Formel folgendermaßen korrigieren:
\begin{center}
\begin{equation} 
score(\bar{B}_j^n, r) = \big(\sum_{1\le m\le b} \bar{B}_j^n(m) * sin_r^m\big)^2 +  \big(\sum_{1\le m\le b} \bar{B}_j^n(m) * cos_r^m\big)^2
\end{equation}
\end{center}

Durch diese einfache Änderung stellten wir bereits eine deutlich reduzierte Erkennungsrate von Pixel fest, welche in dem betrachteten Zeitraum \emph{nur} eine große Amplitude hatten (z.B. dunkle Biene auf hellem Holz).

\subsection{Neues Feature zur Bewertung der Dots}% Simon
Da die Formel zur Bewertung eines Pixel mit all seinen berechneten Frequenzen sehr unintuitiv ist, dachten wir uns vielleicht das man hier eine einfachere und womöglich auch bessere Formel finden können sollte.\\
Die alte Formel:
\begin{center}
\begin{equation} 
potential(D_j)=A^n_j*\sum_{r\in FREQS}w(score(\bar{B}_j^n, r)) * score(\bar{B}_j^n,r)
\end{equation}
\end{center}

Wobei die Funktion $w$ angibt, wieviele Scores kleiner sind, d.h. höhere Scores werden stärker, niedrigere schwächer bewertet. Da in keiner Stelle der Arbeit darauf eingegangen wird, wieso diese Formel an dieser Stelle ihren zweck erfüllt haben wir uns etwas einfacheres ausgedacht.

Als erstes haben wir uns entschieden die Amplitude aus dieser Rechnung zu entfernen, da Sie bereits genutzt wird um zu entscheiden ob der Pixel überhaupt als Dot in betracht gezogen wird. Die zweite Überlegung war, dass wir einfach schauen könnten ob ein Score größer als $x$ ist oder nicht.

\begin{center}
\begin{equation} 
\exists r\in FREQS : x\le score(\bar{B}_j^n, r)
\end{equation}
\end{center}

Da diese Funktion schon sehr vielversprechend arbeitete, jedoch nicht immer alle Waggles erkannt hat, haben wir uns entschieden über jeweils zwei benachbarte Frequenzen die entsprechenden Scores zu summieren und für diese testen ob Sie größer $x$ sind. Diese Änderung hatte den Effekt, das nun auch die Bienen erkannt werden welche genau zwischen zwei Frequenzen tanzen.

\subsection{Probleme des neuen Features und der Frequenanalyse}
Das einzige gravierende Problem welches wir mit dem neuen Feature und der korrigierten Frequenanalyse festgestellt haben ist, dass bei ungünstiger Beleuchtung die Bienen beim sogenannten ventilieren erkannt werden, da der Wechsel von reflektiertem Licht und dunkler Wabe auch in den betrachten Frequenzbereich fällt (bzw. ein vielfachens davon).

Die einfachste möglichkeit dieses Problem zu lösen, welche sehr zuverlässig funktionierte, war die Beleuchtung zu ändern. Als Ideal hat sich diffuse Beleuchtung (z.B. Raumbeleuchtung mit Leuchtröhren) herausgestellt.

Jedoch glauben wir auch dass es ansonsten keine Triviale möglichkeit gibt dieses ventilieren und das tanzen auf dieser Ebene zu unterscheiden, da beides auf die gleichen Frequenzen fällt (bzw. vielfache davon). Eine mögliche Lösung in der Nachbearbeitung währe womöglich die örtlichen Abstände erkannter Waggles zu messen, da sich die Bienen während des ventilierens nicht bewegen und die erkannten Waggles entprechend immer an genau der gleichen Stelle sind. Um an dieser Stelle anzusetzen existiert bereits ein Python Prototyp, siehe Python Prototyp.

\subsection{Parallelisierung der Dotdetection}% Johannes

Während der Laufzeitanalyse des bestehenden Codes ist uns aufgefallen, dass die große Verarbeitungsdauer des Dotdetectorlayers schon bei kleineren Abweichung von den üblichen Parametern (z.B. bei einer höheren Auflösung)
zu Problemen führen kann, insbesondere weil dadurch Videoframes verloren werden, was die Erkennung von Tänzen verfälschen kann.
Um diesen Fehler zu beheben versuchten wir zunächst kleinere, lokale Änderungen einzuführen um zu sehen ob sich das Problem ohne aufwendiges Refactoring beheben liess.
Nach mehrern Profilingdurchgängen war uns aufgefallen, dass vor allem die Dotdetection zeitraubend ist, da für jedes Bildfeld, das einen Dot repräsentiert bei der Detektion ein Schleifendurchlauf nötig ist.
Um diesen Teil des Codes zu beschleunigen, parallelisierten wir diese Schleife.
Hierzu verwendeten wir eine {\tt parallel\_for} Schleife; die kritischen Programmteile innerhalb der Schleife wurden durch Locks geschützt.
Diese Verbesserung war zwar sehr schnell durchgeführt und änderte nichts an der Funktionsweise des Programms, leider war der Geschwindigkeitszugewinn jedoch zu klein um das Problem zu lösen.

\subsection{Dotdetector mit Matrizen}% Roman

\section{Winkelanalyse}% Roman

\subsection{Fitline (Lineare Regression)}% Roman
\subsection{Darstellung in Videos}% Roman


\section{Python Prototyp}% Simon
Gegen Ende des Projektes haben wir noch an einem kleinen Python-Skript gearbeitet, um die gefundenen Waggles zu visualisieren und anhand von Bedingungen (z.B. der maximale/minimale zeitliche und örtliche Abstand von einzelnen Waggles) zu Clustern. Die Visualisierung erfolgt hierbei mithilfe von gnuplot. Zu beachten ist, dass das Skript zur Zeit noch \emph{alle} Waggles die es im angegebenen Ordner findet lädt, dies kann bei vielen Waggles entsprechend lange dauern.

Dieses Projekt ist vermutlich eine gute Stelle um Probleme wie die des neuen Features zur Dotdetection mit ungünstigen Lichverhältnissen in der nachbearbeitung zu lösen.
\subsection{Funktionsübersicht}% Simon
\begin{enumerate}
\item eine Klasse Waggle, welche alle Informationen zu einzelnen Waggles speichert
\item laden aller gefundener Waggles des WDD
\item Clustern der gefunden Waggles anhand von bedingungen (siehe getAllClusters.py, Funktion match)
\item Ausgabe aller gefundenen Waggles/Cluster in eine .csv
\item Visualisierung von Waggles/Clustern\\
\end{enumerate}

\section{Korrektur des Sanitychecks}
Während einigen Tests ist uns aufgefallen, dass man nicht auf der kompletten auflösung von Videos arbeiten konnte da ein Fehlerhafter Sanitycheck auf eine Reduzierung auf mindestens 1/4 bestanden hat.


\end{document}
